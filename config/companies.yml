import os
import json
import requests
from datetime import datetime, timedelta

# --- Configuration ---
# Keywords to define the sectors we are interested in.
SECTOR_KEYWORDS = [
    "igaming",
    "online casino",
    "sports betting",
    "gambling technology",
]

# Keywords to identify relevant financial news announcements.
FINANCIAL_NEWS_KEYWORDS = [
    "financial results",
    "quarterly earnings",
    "quarterly update",
    "annual report",
    "guidance update",
    "earnings call",
    "Q1", "Q2", "Q3", "Q4", # Quarterly reports
    "H1", "H2",             # Half-year reports
    "FY",                   # Full-year reports
    "first quarter",
    "second quarter",
    "third quarter",
    "fourth quarter",
    "full year",
    "half year"
]

# Press wire domains to search. These are the most common sources for official financial news.
PRESS_WIRE_SITES = [
    "businesswire.com",
    "globenewswire.com",
    "prnewswire.com",
]

# --- Core Functions ---

def construct_discovery_queries():
    """
    Creates broad search queries to discover recent financial news across the entire sector.
    """
    # Combine sector and financial keywords into search strings
    sector_query_part = " OR ".join([f'"{kw}"' for kw in SECTOR_KEYWORDS])
    financial_query_part = " OR ".join([f'"{kw}"' for kw in FINANCIAL_NEWS_KEYWORDS])
    
    # Restrict search to trusted press wire sites
    site_query_part = " OR ".join([f'site:{site}' for site in PRESS_WIRE_SITES])
    
    # Build the final, powerful query
    # This looks for documents on specific sites that contain at least one sector keyword
    # and at least one financial news keyword.
    final_query = f"({sector_query_part}) AND ({financial_query_part}) AND ({site_query_part})"
    
    # We can also create more targeted queries if needed, but one powerful query is often best
    return [final_query]

def search_google(query):
    """
    Performs a Google search using a simulated API call.
    In a real-world scenario, you would use a proper API like Google's Custom Search JSON API.
    This is a placeholder to demonstrate the logic.
    """
    print(f"  Executing search: {query}\n")
    # This is where you would make an actual API call.
    # To make this functional, you would need to integrate a real search API.
    # Example using a hypothetical 'google_search' tool:
    # from google_search import search
    # return search(queries=[query])
    #
    # For this example, we'll return mock data that resembles a real API response.
    return [
        {
            "title": "Vegas Gaming Inc. Reports Record Q2 2024 Financial Results",
            "link": "https://www.businesswire.com/news/home/20240812123456/en/",
            "snippet": "Vegas Gaming Inc. (NASDAQ: VGAM) today announced financial results for the second quarter (Q2) ended June 30, 2024, highlighting strong growth in its iGaming division.",
            "published_date": (datetime.now() - timedelta(days=2)).isoformat(),
            "source": "businesswire.com"
        },
        {
            "title": "Global Sports Betting Solutions Provides FY24 Guidance Update",
            "link": "https://www.globenewswire.com/news-release/2024/08/10/12345.html",
            "snippet": "Global Sports Betting Solutions (OTC: GSBS) has updated its full-year (FY) 2024 guidance following a successful H1 driven by market expansion.",
            "published_date": (datetime.now() - timedelta(days=4)).isoformat(),
            "source": "globenewswire.com"
        }
    ]

def find_sector_wide_updates():
    """
    Finds the latest financial news across the entire iGaming and sports betting sector.
    """
    queries = construct_discovery_queries()
    all_articles = []
    seen_urls = set()

    for query in queries:
        try:
            # In a real implementation, you'd call a real search API here.
            results = search_google(query) # Using mock data for now

            for result in results:
                url = result.get("link")
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    all_articles.append({
                        "title": result.get("title", "No Title"),
                        "url": url,
                        "snippet": result.get("snippet", "No Snippet"),
                        "source": result.get("source", "Unknown Source"),
                        "published": result.get("published_date", "N/A")
                    })

        except Exception as e:
            print(f"  [!] Error searching for query '{query}': {e}")
            continue
            
    return all_articles


# --- Main Execution ---

if __name__ == "__main__":
    print("--- iGaming & Sports Betting Financial News Discovery Tool ---")
    print("Searching for recent financial updates across the sector...\n")
    
    articles = find_sector_wide_updates()
    
    if articles:
        print(f"--- Found {len(articles)} recent financial updates ---")
        # Sort articles by date, newest first
        for article in sorted(articles, key=lambda x: x.get('published', ''), reverse=True):
            print(f"\n  ðŸ“„ Title: {article['title']}")
            print(f"     Source: {article['source']}")
            print(f"     Published: {article['published']}")
            print(f"     URL: {article['url']}")
            print(f"     Snippet: {article['snippet']}")
        print("\n" + "="*50)
    else:
        print("--- No recent articles found based on the mock data. ---")

    print("\nScript finished.")
